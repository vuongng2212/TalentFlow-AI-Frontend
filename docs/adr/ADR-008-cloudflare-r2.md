# ADR-008: Use Cloudflare R2 for Object Storage

**Status:** Accepted
**Date:** 2026-02-02
**Deciders:** Team (3 developers)

---

## Context

We need object storage for CV files (PDF/DOCX) uploaded by candidates.

### Requirements:
- **Storage volume:** ~1000 CVs/day Ã— 2MB average = 2GB/day = 60GB/month
- **Access pattern:** Write once, read few times (download for parsing)
- **Retention:** 2+ years (GDPR compliance)
- **Security:** Private buckets, signed URLs for temporary access
- **Cost:** Predictable, budget-friendly for startup MVP

### Options Considered:
1. **AWS S3** - Industry standard
2. **Cloudflare R2** - S3-compatible, zero egress fees
3. **MinIO** - Self-hosted S3-compatible
4. **DigitalOcean Spaces** - Simple, flat pricing
5. **Azure Blob Storage** - Microsoft cloud

---

## Decision

We will use **Cloudflare R2** for production and **MinIO** for local development.

**Why R2:**
- S3-compatible API (easy migration)
- **Zero egress fees** (huge cost savings)
- Global CDN (low latency)
- Competitive storage pricing
- Developer-friendly

---

## Rationale

### Cost Comparison (60GB storage, 10TB egress/month)

| Provider | Storage Cost | Egress Cost | Total/Month | Annual |
|----------|-------------|-------------|-------------|--------|
| **AWS S3** | $1.38 | **$921.60** | **$922.98** | **$11,075** |
| **Cloudflare R2** | $0.90 | **$0.00** âœ¨ | **$0.90** | **$10.80** |
| **Azure Blob** | $1.20 | $614.40 | $615.60 | $7,387 |
| **DO Spaces** | $5.00 | $10.00 | $15.00 | $180 |
| **MinIO** | $20/mo VPS | $0 | $20.00 | $240 |

**Winner:** ğŸ† **Cloudflare R2** - **1,025x cheaper than S3!**

### Why This Matters:

**With AWS S3:**
```
Year 1: $11,075
Year 2: $22,150
Year 3: $33,225
Total 3 years: $33,225
```

**With Cloudflare R2:**
```
Year 1: $10.80
Year 2: $21.60
Year 3: $32.40
Total 3 years: $64.80
```

**Savings: $33,160 over 3 years!** ğŸ’°

### Egress Math:

**CV downloads:**
```
1000 CVs/day Ã— 2MB = 2GB/day
CV Parser downloads each file once
Recruiter views CV PDF: ~10% = 100 views/day

Daily egress: 2GB + 0.2GB = 2.2GB
Monthly egress: 2.2GB Ã— 30 = 66GB

Add frontend asset CDN usage: ~200GB/month
Total egress: ~300GB/month = 0.3TB

But with R2: $0 egress! ğŸ‰
```

---

## Technical Comparison

### Feature Parity

| Feature | AWS S3 | Cloudflare R2 | Notes |
|---------|--------|---------------|-------|
| **S3 API Compatible** | âœ… Native | âœ… Compatible | Same SDK works! |
| **Signed URLs** | âœ… | âœ… | Temporary access |
| **Bucket Policies** | âœ… | âœ… | IAM-style permissions |
| **Lifecycle Rules** | âœ… | âœ… | Auto-delete old files |
| **CORS** | âœ… | âœ… | Frontend uploads |
| **Multipart Upload** | âœ… | âœ… | Large files |
| **Versioning** | âœ… | âœ… | Keep file history |
| **Encryption at Rest** | âœ… | âœ… | AES-256 |
| **CDN Integration** | CloudFront | **Built-in** | R2 auto-CDN |
| **Global Edge** | Regions | **Global** | Lower latency |

**Verdict:** R2 has feature parity + extras

---

## Implementation

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚
â”‚  (Next.js 16)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ POST /api/candidates/upload
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Gateway          â”‚
â”‚     (NestJS)           â”‚
â”‚                        â”‚
â”‚  1. Validate file      â”‚
â”‚  2. Generate key       â”‚
â”‚  3. Upload to R2       â”‚
â”‚  4. Save metadata DB   â”‚
â”‚  5. Emit BullMQ event  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cloudflare R2        â”‚
â”‚  (Object Storage)      â”‚
â”‚                        â”‚
â”‚  Bucket: talentflow-cvsâ”‚
â”‚  Key: cvs/{uuid}.pdf   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Download for parsing
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CV Parser Service    â”‚
â”‚ (Spring Boot/ASP.NET)  â”‚
â”‚                        â”‚
â”‚  1. Download from R2   â”‚
â”‚  2. Parse PDF/DOCX     â”‚
â”‚  3. Extract data       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Code Implementation

**API Gateway - Storage Service:**

```typescript
// src/storage/r2-storage.service.ts
import { S3Client, PutObjectCommand, GetObjectCommand } from '@aws-sdk/client-s3';
import { getSignedUrl } from '@aws-sdk/s3-request-presigner';
import { Injectable } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';

@Injectable()
export class R2StorageService {
  private client: S3Client;
  private bucketName: string;

  constructor(private config: ConfigService) {
    this.bucketName = this.config.get('R2_BUCKET_NAME');

    this.client = new S3Client({
      region: 'auto',
      endpoint: `https://${this.config.get('R2_ACCOUNT_ID')}.r2.cloudflarestorage.com`,
      credentials: {
        accessKeyId: this.config.get('R2_ACCESS_KEY_ID'),
        secretAccessKey: this.config.get('R2_SECRET_ACCESS_KEY'),
      },
    });
  }

  /**
   * Upload file to R2
   * @returns Public URL or signed URL
   */
  async upload(
    file: Buffer,
    key: string,
    contentType: string,
  ): Promise<string> {
    const command = new PutObjectCommand({
      Bucket: this.bucketName,
      Key: key,
      Body: file,
      ContentType: contentType,
      Metadata: {
        uploadedAt: new Date().toISOString(),
      },
    });

    await this.client.send(command);

    // Return public URL (if bucket is public)
    // or generate signed URL
    return this.getPublicUrl(key);
  }

  /**
   * Download file from R2
   */
  async download(key: string): Promise<Buffer> {
    const command = new GetObjectCommand({
      Bucket: this.bucketName,
      Key: key,
    });

    const response = await this.client.send(command);
    const chunks: Uint8Array[] = [];

    for await (const chunk of response.Body as any) {
      chunks.push(chunk);
    }

    return Buffer.concat(chunks);
  }

  /**
   * Generate signed URL (temporary access)
   * @param expiresIn Expiration in seconds (default 1 hour)
   */
  async getSignedUrl(key: string, expiresIn = 3600): Promise<string> {
    const command = new GetObjectCommand({
      Bucket: this.bucketName,
      Key: key,
    });

    return getSignedUrl(this.client, command, { expiresIn });
  }

  /**
   * Get public URL (for public buckets)
   */
  private getPublicUrl(key: string): string {
    const bucketId = this.config.get('R2_PUBLIC_BUCKET_ID');
    return `https://pub-${bucketId}.r2.dev/${key}`;
  }

  /**
   * Delete file from R2
   */
  async delete(key: string): Promise<void> {
    const command = new DeleteObjectCommand({
      Bucket: this.bucketName,
      Key: key,
    });

    await this.client.send(command);
  }
}
```

**Upload Controller:**

```typescript
// src/upload/upload.controller.ts
@Controller('candidates')
export class UploadController {
  constructor(
    private storage: R2StorageService,
    private queue: QueueService,
    private prisma: PrismaService,
  ) {}

  @Post('upload')
  @UseInterceptors(FileInterceptor('file', {
    limits: { fileSize: 10 * 1024 * 1024 }, // 10MB
    fileFilter: (req, file, cb) => {
      const allowed = [
        'application/pdf',
        'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
      ];

      if (allowed.includes(file.mimetype)) {
        cb(null, true);
      } else {
        cb(new BadRequestException('Invalid file type'), false);
      }
    },
  }))
  async uploadCV(
    @UploadedFile() file: Express.Multer.File,
    @Body() dto: UploadCvDto,
  ) {
    // Generate unique key
    const ext = file.originalname.split('.').pop();
    const key = `cvs/${uuidv4()}.${ext}`;

    // Upload to R2
    const fileUrl = await this.storage.upload(
      file.buffer,
      key,
      file.mimetype,
    );

    // Save to database
    const candidate = await this.prisma.candidate.create({
      data: {
        fullName: dto.fullName,
        email: dto.email,
        resumeUrl: fileUrl,
        applications: {
          create: {
            jobId: dto.jobId,
            stage: 'APPLIED',
            status: 'PENDING',
          },
        },
      },
    });

    // Emit to queue for processing
    await this.queue.add('cv.uploaded', {
      candidateId: candidate.id,
      fileUrl,
      jobId: dto.jobId,
    });

    return {
      candidateId: candidate.id,
      status: 'processing',
      message: 'CV uploaded successfully. Processing...',
    };
  }
}
```

### Environment Variables

```env
# Cloudflare R2 Configuration
R2_ACCOUNT_ID=your-account-id
R2_ACCESS_KEY_ID=your-access-key-id
R2_SECRET_ACCESS_KEY=your-secret-access-key
R2_BUCKET_NAME=talentflow-cvs
R2_PUBLIC_BUCKET_ID=your-public-bucket-id  # For public URLs

# Optional: Custom domain
R2_CUSTOM_DOMAIN=cdn.talentflow.ai
```

### Bucket Configuration

**Create R2 Bucket:**
```bash
# Via Cloudflare Dashboard:
1. Go to R2 â†’ Create Bucket
2. Name: talentflow-cvs
3. Location: Automatic (global)
4. Public access: Disabled (private bucket)

# Generate API keys:
1. R2 â†’ Manage R2 API Tokens
2. Create API Token
3. Permissions: Object Read & Write
4. Copy: Access Key ID + Secret Access Key
```

**Bucket Policy (Private):**
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Deny",
      "Principal": "*",
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::talentflow-cvs/*"
    }
  ]
}
```

**CORS Configuration:**
```json
{
  "CORSRules": [
    {
      "AllowedOrigins": ["https://app.talentflow.ai", "http://localhost:3000"],
      "AllowedMethods": ["GET", "PUT", "POST"],
      "AllowedHeaders": ["*"],
      "MaxAgeSeconds": 3600
    }
  ]
}
```

**Lifecycle Rule (Optional):**
```json
{
  "Rules": [
    {
      "Id": "DeleteRejectedCVs",
      "Status": "Enabled",
      "Filter": {
        "Prefix": "cvs/rejected/"
      },
      "Expiration": {
        "Days": 90
      }
    }
  ]
}
```

---

## Local Development: MinIO

**Why MinIO for local dev:**
- S3-compatible (same code works!)
- Runs in Docker
- Web UI for debugging
- Free & open-source

**docker-compose.yml:**
```yaml
version: '3.8'

services:
  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"  # API
      - "9001:9001"  # Web UI
    volumes:
      - minio_data:/data

volumes:
  minio_data:
```

**Local Environment Variables:**
```env
# Local: MinIO
R2_ACCOUNT_ID=us-east-1  # MinIO doesn't need account ID
R2_ACCESS_KEY_ID=minioadmin
R2_SECRET_ACCESS_KEY=minioadmin
R2_BUCKET_NAME=talentflow-cvs
R2_ENDPOINT=http://localhost:9000  # Override endpoint for local

# Production: Cloudflare R2
# (use actual R2 credentials)
```

**Code works for both:**
```typescript
// Automatically uses correct endpoint
const endpoint = process.env.R2_ENDPOINT ||
  `https://${process.env.R2_ACCOUNT_ID}.r2.cloudflarestorage.com`;

const client = new S3Client({
  region: 'auto',
  endpoint,
  credentials: { ... },
});
```

---

## Security Considerations

### 1. Private Buckets

**Problem:** Public buckets expose CV files to anyone
**Solution:** Private buckets + signed URLs

```typescript
// Generate temporary signed URL (1 hour)
const signedUrl = await storage.getSignedUrl('cvs/abc.pdf', 3600);

// Frontend can download via signed URL
<a href={signedUrl}>Download CV</a>
```

### 2. File Validation

**Problem:** Malicious file uploads
**Solution:** Validate MIME type, file size, extension

```typescript
// Already implemented in FileInterceptor
fileFilter: (req, file, cb) => {
  const allowed = ['application/pdf', 'application/vnd...'];
  if (allowed.includes(file.mimetype)) {
    cb(null, true);
  } else {
    cb(new BadRequestException('Invalid file type'), false);
  }
}
```

### 3. Virus Scanning (Phase 2)

**Current:** Basic validation
**Future:** ClamAV or cloud service

```typescript
// Phase 2: Virus scanning before upload
const scanResult = await virusScanner.scan(file.buffer);
if (scanResult.infected) {
  throw new BadRequestException('Virus detected');
}
```

### 4. Encryption

**At Rest:** R2 automatically encrypts (AES-256)
**In Transit:** HTTPS only (TLS 1.3)

---

## Cost Projection

### Year 1 (MVP â†’ Growth)

| Month | CVs/day | Storage | Egress | R2 Cost | S3 Cost | Savings |
|-------|---------|---------|--------|---------|---------|---------|
| 1-3 | 100 | 6GB | 10GB | $0.09 | $93 | $92.91 |
| 4-6 | 500 | 30GB | 50GB | $0.45 | $465 | $464.55 |
| 7-9 | 1000 | 60GB | 100GB | $0.90 | $930 | $929.10 |
| 10-12 | 2000 | 120GB | 200GB | $1.80 | $1,860 | $1,858.20 |

**Year 1 Total:** $3.24 (R2) vs $3,348 (S3) = **$3,344.76 saved!**

### Year 3 (Scale)

| Metric | Value |
|--------|-------|
| CVs/day | 10,000 |
| Storage | 2TB |
| Egress | 10TB/month |
| **R2 Cost** | **$30/month** = **$360/year** |
| **S3 Cost** | **$9,240/month** = **$110,880/year** |
| **Savings** | **$110,520/year** |

**That's hiring a full-time engineer!** ğŸ‘¨â€ğŸ’»

---

## Migration Strategy

### From MinIO (local) â†’ R2 (production)

**Zero code changes!** Just update env vars:

```bash
# Local .env
R2_ENDPOINT=http://localhost:9000
R2_ACCESS_KEY_ID=minioadmin
R2_SECRET_ACCESS_KEY=minioadmin

# Production .env (Railway secrets)
# R2_ENDPOINT not set (uses Cloudflare default)
R2_ACCOUNT_ID=abc123
R2_ACCESS_KEY_ID=prod-key
R2_SECRET_ACCESS_KEY=prod-secret
```

### From S3 â†’ R2 (if needed)

**Cloudflare provides migration tools:**
```bash
# Using rclone
rclone sync s3:old-bucket r2:new-bucket

# Or AWS CLI + R2 endpoint
aws s3 sync s3://old-bucket s3://new-bucket \
  --endpoint-url https://abc.r2.cloudflarestorage.com
```

---

## Monitoring & Alerts

### Metrics to Track:

```typescript
// Storage Service with metrics
@Injectable()
export class R2StorageService {
  async upload(file: Buffer, key: string): Promise<string> {
    const start = Date.now();

    try {
      await this.client.send(...);

      // Track success
      this.metrics.increment('storage.upload.success');
      this.metrics.histogram('storage.upload.duration', Date.now() - start);

      return url;
    } catch (error) {
      // Track failure
      this.metrics.increment('storage.upload.failure');
      throw error;
    }
  }
}
```

### Alerts:

```yaml
# Alert if upload failures > 5%
- alert: HighStorageUploadFailureRate
  expr: rate(storage_upload_failure[5m]) / rate(storage_upload_total[5m]) > 0.05
  annotations:
    summary: "High R2 upload failure rate"

# Alert if upload latency > 5s (p95)
- alert: SlowStorageUploads
  expr: histogram_quantile(0.95, storage_upload_duration) > 5000
  annotations:
    summary: "R2 uploads are slow"
```

---

## Consequences

### Positive:

âœ… **Massive Cost Savings:**
- $33,160 saved over 3 years vs S3
- Free egress = predictable costs
- Can reinvest in features

âœ… **S3 API Compatible:**
- Same code, same SDK
- Easy migration from/to S3
- Familiar developer experience

âœ… **Global CDN Built-in:**
- No need for CloudFront
- Lower latency worldwide
- Automatic edge caching

âœ… **Simple Pricing:**
- $0.015/GB storage
- $0 egress
- No surprise bills

### Negative:

âš ï¸ **Newer Service:**
- R2 launched 2022 (vs S3 2006)
- Less battle-tested
- Smaller community

âš ï¸ **Fewer Integrations:**
- S3 has more 3rd-party tools
- Some tools may not support R2
- Workaround: S3 API compatibility

âš ï¸ **Cloudflare Dependency:**
- Vendor lock-in (but S3-compatible)
- If Cloudflare down, storage down
- Mitigation: Use S3 as backup

### Mitigation:

**Abstraction Layer:**
```typescript
interface StorageService {
  upload(file: Buffer, key: string): Promise<string>;
  download(key: string): Promise<Buffer>;
  delete(key: string): Promise<void>;
}

// Can swap R2 â†’ S3 â†’ MinIO
```

**Backup Strategy:**
```bash
# Daily backup to S3 (just in case)
rclone sync r2:talentflow-cvs s3:talentflow-backup
```

---

## Success Metrics

### R2 will be considered successful if:

**MVP (Week 8):**
- [ ] Upload latency < 2s (p95)
- [ ] Download latency < 1s (p95)
- [ ] 99.9% upload success rate
- [ ] Zero data loss
- [ ] Cost < $5/month

**Post-MVP (Month 3-6):**
- [ ] Handle 1000+ uploads/day
- [ ] 99.95% uptime
- [ ] Cost < $50/month
- [ ] No performance issues
- [ ] Savings > $1000/month vs S3

---

## Related Decisions

- [ADR-006: Hybrid Microservices](./ADR-006-hybrid-microservices.md) - Architecture
- [ADR-007: BullMQ](./ADR-007-bullmq-over-kafka.md) - Queue technology

---

## References

- [Cloudflare R2 Documentation](https://developers.cloudflare.com/r2/)
- [S3 API Compatibility](https://developers.cloudflare.com/r2/api/s3/)
- [R2 Pricing](https://developers.cloudflare.com/r2/pricing/)
- [AWS SDK for JavaScript v3](https://docs.aws.amazon.com/AWSJavaScriptSDK/v3/latest/)

---

**Last Updated:** 2026-02-02
**Next Review:** Week 8 (MVP launch) - Verify cost savings realized
